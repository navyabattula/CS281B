{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f808795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d168b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 10\n",
    "batch_size = 16\n",
    "epsilon_std = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c4a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2a692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder():\n",
    "    img = Input(shape=img_shape)\n",
    "    h = Flatten()(img)\n",
    "    h = Dense(512)(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    h = Dense(512)(h)\n",
    "    h = LeakyReLU(alpha=0.2)(h)\n",
    "    mu = Dense(latent_dim)(h)\n",
    "    log_var = Dense(latent_dim)(h)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([mu, log_var])\n",
    "    return Model(img, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd0bce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    # tanh is more robust: gradient not equal to 0 around 0\n",
    "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "    model.add(Reshape(img_shape))\n",
    "    model.summary()\n",
    "    z = Input(shape=(latent_dim,))\n",
    "    img = model(z)\n",
    "    return Model(z, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e880d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.summary()\n",
    "    encoded_repr = Input(shape=(latent_dim,))\n",
    "    validity = model(encoded_repr)\n",
    "    return Model(encoded_repr, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b6ff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,217\n",
      "Trainable params: 137,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 784)               402192    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 670,480\n",
      "Trainable params: 670,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 13:41:27.188302: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-03 13:41:27.188512: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Build the encoder / decoder\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "\n",
    "img = Input(shape=img_shape)\n",
    "# The generator takes the image, encodes it and reconstructs it\n",
    "# from the encoding\n",
    "encoded_repr = encoder(img)\n",
    "reconstructed_img = decoder(encoded_repr)\n",
    "\n",
    "# For the adversarial_autoencoder model we will only train the generator\n",
    "# if discriminator is attached to generator, set this flag\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator determines validity of the encoding\n",
    "validity = discriminator(encoded_repr)\n",
    "\n",
    "# The adversarial_autoencoder model  (stacked generator and discriminator)\n",
    "adversarial_autoencoder = Model(img, [reconstructed_img, validity])\n",
    "adversarial_autoencoder.compile(loss=['mse', 'binary_crossentropy'], loss_weights=[0.999, 0.001], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d75fb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, sample_interval=50):\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #  Train Discriminator\n",
    "\n",
    "        # Select a random batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        latent_fake = encoder.predict(imgs)\n",
    "        latent_real = np.random.normal(size=(batch_size, latent_dim))\n",
    "\n",
    "        # Train the discriminator\n",
    "        # let latent_real's output is close to 1\n",
    "        d_loss_real = discriminator.train_on_batch(latent_real, valid)\n",
    "        # let latent_fake's output is close to 0\n",
    "        d_loss_fake = discriminator.train_on_batch(latent_fake, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        # decrease reconstruction error and let discriminator's output is close to 1\n",
    "        g_loss = adversarial_autoencoder.train_on_batch(imgs, [imgs, valid])\n",
    "\n",
    "        # If at save interval\n",
    "        if epoch % sample_interval == 0:\n",
    "            # Plot the progress\n",
    "            print(\"%d [D loss: %f, acc: %.2f%%] [G loss: %f, mse: %f]\" % (\n",
    "                epoch, d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[1]))\n",
    "            # save generated image samples\n",
    "            sample_images(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e464f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save generated images per specified epochs \n",
    "def sample_images(epoch):\n",
    "    r, c = 5, 5\n",
    "    z = np.random.normal(size=(r * c, latent_dim))\n",
    "    gen_imgs = decoder.predict(z)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1525ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "sample_interval = 200\n",
    "sample_count = epochs/sample_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fa7e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.103427, acc: 100.00%] [G loss: 0.128783, mse: 0.124947]\n",
      "200 [D loss: 0.027318, acc: 100.00%] [G loss: 0.128162, mse: 0.121963]\n",
      "400 [D loss: 0.031518, acc: 100.00%] [G loss: 0.120810, mse: 0.114941]\n",
      "600 [D loss: 0.117582, acc: 96.88%] [G loss: 0.140280, mse: 0.135002]\n",
      "800 [D loss: 0.041429, acc: 100.00%] [G loss: 0.106231, mse: 0.099515]\n",
      "1000 [D loss: 0.268492, acc: 84.38%] [G loss: 0.101388, mse: 0.097651]\n",
      "1200 [D loss: 0.301951, acc: 84.38%] [G loss: 0.125646, mse: 0.122880]\n",
      "1400 [D loss: 0.274343, acc: 84.38%] [G loss: 0.084848, mse: 0.082152]\n",
      "1600 [D loss: 0.346143, acc: 87.50%] [G loss: 0.082015, mse: 0.079613]\n",
      "1800 [D loss: 0.359963, acc: 87.50%] [G loss: 0.086735, mse: 0.083982]\n"
     ]
    }
   ],
   "source": [
    "train(epochs=epochs, batch_size=batch_size, sample_interval=sample_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe44ae5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
